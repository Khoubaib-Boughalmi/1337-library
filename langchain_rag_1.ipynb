{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SrbltmYiuCDrhcKQVswQmGEKvVz9RnZE",
      "authorship_tag": "ABX9TyNhYiTyXhYv6OdsqdWp4nCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khoubaib-Boughalmi/1337-library/blob/main/langchain_rag_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QDhuMQA5cW1a"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade langchain-core langchain-text-splitters faiss-cpu langchain-community langgraph beautifulsoup4 langchain-google-vertexai google-cloud-aiplatform pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import os\n",
        "\n",
        "pdf_directory = \"/content/drive/MyDrive/RCDH/\"\n",
        "pdf_docs = []\n",
        "\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(os.path.join(pdf_directory, filename))\n",
        "        pdf_docs.extend(loader.load())\n"
      ],
      "metadata": {
        "id": "Ptyqrb7zsVLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb64091-35c7-4ec2-8c93-e7b0f441c0ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 57 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Only keep post title, headers, and content from the full HTML.\n",
        "bs4_strainer = bs4.SoupStrainer(id=\"bodyContent\")\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://en.wikipedia.org/wiki/Saudi_Authority_for_Data_and_Artificial_Intelligence\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "docs = loader.load() # 1 doc (1 page)\n",
        "\n",
        "assert len(docs) == 1\n",
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7yFkJTldAFA",
        "outputId": "e2876cf6-29cf-43ce-b2b6-86ff0b173108"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 2442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from langchain.schema import Document\n",
        "\n",
        "url = \"https://bcg.trial.opendatasoft.com/api/explore/v2.1/catalog/datasets/saudi-aircraft-traffic-passenger-and-cargo-by-domestic-airports/exports/csv?lang=en&timezone=Africa%2FLagos&use_labels=true&delimiter=%3B\"\n",
        "\n",
        "headers = {\n",
        "    \"X-CSRFToken\": \"ofJ7t5RQM9sRsave0osExvD3fifDG1qN\",\n",
        "    \"User-Agent\": \"Mozilla/5.0\"\n",
        "}\n",
        "\n",
        "cookies = {\n",
        "    \"sessionid\": \"sk4xbp4dx8svwtkiss13bywu1va8ymfw\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, cookies=cookies)\n",
        "csv_path = \"/content/drive/MyDrive/RCDH/data.csv\"\n",
        "if response.status_code == 200:\n",
        "    with open(csv_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(f\"Failed to fetch data: {response.status_code}\")\n",
        "\n",
        "df = pd.read_csv(csv_path, delimiter=\";\")\n",
        "print(\"CSV loaded into DataFrame.\")\n",
        "\n",
        "# Step 3: Convert DataFrame rows into LangChain `Document` objects\n",
        "csv_docs = []\n",
        "for _, row in df.iterrows():\n",
        "    content = \"\\n\".join(f\"{col}: {val}\" for col, val in row.items())\n",
        "    csv_docs.append(Document(page_content=content))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T0KTTf-EjOu",
        "outputId": "b3bfafe6-e2b8-4162-9555-b284612f143d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV loaded into DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(csv_docs[0].page_content[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XnfTQSsdBuK",
        "outputId": "5d23fa5a-c624-421e-d7b9-06ab6014a9fa"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year: 2013\n",
            "Arr/Dep: Arr. Cargo (kgs)\n",
            "Domestic Airport: Riyadh\n",
            "Aircraft Traffic : 117251302.0\n",
            "Lat, Long: 24.9427121, 46.7123544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = docs + pdf_docs + csv_docs\n",
        "print(f\"Total documents: {len(all_docs)}\")\n",
        "print(len(docs))\n",
        "print(len(pdf_docs))\n",
        "print(len(csv_docs))\n"
      ],
      "metadata": {
        "id": "5BcV1yG-srq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66bf6f3a-049a-406e-858c-a787e71a3ae4"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total documents: 57\n",
            "1\n",
            "20\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    add_start_index=True,\n",
        ")\n",
        "all_splits = text_splitter.split_documents(all_docs)\n",
        "print(f\"Split into {len(all_splits)} chunks\")"
      ],
      "metadata": {
        "id": "sAMhPKQveBfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54ecbaa-04b3-4ce0-87c3-2af3180f3f5e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 94 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_splits[91])"
      ],
      "metadata": {
        "id": "t1gPTlngeMal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98c40ca-007b-4dd9-d669-5889bebeeb15"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Year: 2016\n",
            "Arr/Dep: Arr. Cargo (kgs)\n",
            "Domestic Airport: Riyadh\n",
            "Aircraft Traffic : 93127333.0\n",
            "Lat, Long: 24.9427121, 46.7123544' metadata={'start_index': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/gen-lang-client-0716959645-1c6625495b1d.json\""
      ],
      "metadata": {
        "id": "nFc_sGJLoXgL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat {os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")}"
      ],
      "metadata": {
        "id": "Sy0x0_zwoi8r"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_vertexai import VertexAIEmbeddings\n",
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.docstore.document import Document\n",
        "# from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "\n",
        "# # os.environ[\"GOOGLE_CLOUD_REGION\"] = \"me-central2\"\n",
        "\n",
        "# # Initialize Vertex AI Embeddings\n",
        "# embedding_model = VertexAIEmbeddings(\n",
        "#     model_name=\"textembedding-gecko@001\",  # Required!\n",
        "# )\n",
        "\n",
        "# # Initialize Vertex AI Embeddings\n",
        "# embedding_model = VertexAIEmbeddings()\n",
        "\n",
        "# # Sample documents\n",
        "# documents = [\n",
        "#     Document(page_content=\"LangChain is a framework for building LLM-powered apps.\"),\n",
        "#     Document(page_content=\"Google Vertex AI provides powerful models like Gemini.\"),\n",
        "# ]\n",
        "\n",
        "# # Initialize with an embedding model\n",
        "# vector_store = InMemoryVectorStore(embedding=embedding_model())\n"
      ],
      "metadata": {
        "id": "aX6L3Qnjpjia"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize local embedding model using sentence-transformers\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "content_list = [doc.page_content for doc in all_splits]\n",
        "vector_store = FAISS.from_texts(content_list, embedding_model)\n"
      ],
      "metadata": {
        "id": "PQlKm-TBgMGb"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rag_prompt(query, relevant_passage):\n",
        "    relevant_passage = ' '.join(relevant_passage)\n",
        "    return (\n",
        "        \"You are a helpful chatbot on a Saudi government website, answering inquiries from Saudi Arabian citizens. \"\n",
        "        \"Your responses should be based **only on the retrieved reference content** provided below.\\n\\n\"\n",
        "        \"Instructions:\\n\"\n",
        "        \"1. The question may be in Arabic, colloquial Arabic, or English — adapt accordingly.\\n\"\n",
        "        \"2. Some terminology may be loosely translated (e.g., 'نظام حماية البيانات الشخصية' might appear as 'personal data protection system'). \"\n",
        "        \"Use your judgment to interpret such terms accurately if they are clearly related.\\n\"\n",
        "        \"3. Do not guess or add information not found in the provided content.\\n\"\n",
        "        \"4. If the context doesn't contain relevant information, respond politely and state that the answer is not available.\\n\"\n",
        "        \"5. Use a clear, friendly, and easy-to-understand tone suitable for a general audience.\\n\\n\"\n",
        "        f\"QUESTION: '{query}'\\n\"\n",
        "        f\"CONTEXT: '{relevant_passage}'\\n\\n\"\n",
        "        f\"ANSWER:\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "TQEVd5NzNS1n"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_translation_prompt(query):\n",
        "\n",
        "  translation_prompt = (\n",
        "      \"You will be given a question that may be in Arabic, Saudi dialect, or English.\\n\"\n",
        "      \"Your task is to return a clear and grammatically correct version of the question in English, suitable for use in a search engine.\\n\"\n",
        "      \"If the question is in Arabic or dialect, translate it to English.\\n\"\n",
        "      \"If it's already in English, fix any grammar, typos, or unclear phrases but keep it in English.\\n\\n\"\n",
        "      f\"QUESTION:\\n{query}\\n\\n\"\n",
        "      \"REWRITE IN ENGLISH:\"\n",
        ")\n",
        "  return translation_prompt\n"
      ],
      "metadata": {
        "id": "ZnuRLnlK7chr"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.generativeai as genai\n",
        "\n",
        "# genai.configure(api_key=\"AIzaSyDXM2rYFwObTTIFrJLMgVTvfjEaGwqj_D0\")\n",
        "# def generate_response(user_prompt):\n",
        "#     model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
        "#     answer = model.generate_content(user_prompt)\n",
        "#     return answer.text"
      ],
      "metadata": {
        "id": "78JQRUzhPLDt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "def init_model():\n",
        "  genai.configure(api_key=\"AIzaSyDXM2rYFwObTTIFrJLMgVTvfjEaGwqj_D0\")\n",
        "  model = genai.GenerativeModel('gemini-1.5-flash-002')\n",
        "  return model\n",
        "\n",
        "model = init_model()\n",
        "\n"
      ],
      "metadata": {
        "id": "CClCHlrP8ejS"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query: str):\n",
        "    query = make_translation_prompt(query)\n",
        "    normalized_query = model.generate_content(query)\n",
        "    query = normalized_query.text\n",
        "    return vector_store.similarity_search(query)\n"
      ],
      "metadata": {
        "id": "GbKa6DWTvXMg"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str) -> list[float]:\n",
        "    return embedding_model.embed_query(text)\n"
      ],
      "metadata": {
        "id": "VqNjQvE-wWmc"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(user_prompt):\n",
        "    answer = model.generate_content(user_prompt)\n",
        "    return answer.text"
      ],
      "metadata": {
        "id": "DZVtEA7-NYdH"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query):\n",
        "    relevant_text = retrieve(query)\n",
        "    text = \" \".join([doc.page_content for doc in relevant_text])\n",
        "    prompt = make_rag_prompt(query, relevant_passage=text)\n",
        "    answer = generate_response(prompt)\n",
        "    return answer\n",
        "answer = generate_answer(\"ين هي الهيئة السعودية للبيانات والذكاء الاصطناعي\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bfCXsUoOvhuh",
        "outputId": "c150465f-da68-4ef8-9075-ca6cd5dc50ac"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Saudi Data and AI Authority (SDAIA) is a government agency in Saudi Arabia established on August 30, 2019, by a royal decree.  It oversees digital platforms such as Nafath (Unified National Access) and Tawakkalna.  The agency is directly linked to the Prime Minister and governed by a board of directors chaired by the Deputy Prime Minister.  It also has three other bodies linked to it: The National Center for Artificial Intelligence, The National Data Management Office, and the National Information Center.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش مزوّدي الخدمة الموجودين في السعودية؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "sN0HwQaiNXba",
        "outputId": "35838e0b-553d-422a-ba5a-96b0d4f13d23"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, Alibaba Cloud, Google Cloud (in Dammam), and Oracle (in Riyadh/ Jeddah) are service providers with a presence in Saudi Arabia.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش اسم نموذج علي بابا؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "3JUAoW2tixP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "376b5149-f157-4953-a051-deef8047a9ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Alibaba model mentioned in the text is called Qwen.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش أكبر النماذج المتوفرة؟ وإذا تقدر، عطِني أرقام.\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "o5lVxpL4uCjF",
        "outputId": "0fc7bddc-c0d0-4cb0-bc4f-0c07716a62ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The passage mentions several large language models, including Google's Gemini, OpenAI's ChatGPT, Oracle's AI, and Alibaba's Qwen.  However, it doesn't provide specific numerical details about their sizes.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش نقاط القوة والضعف في كل نموذج؟\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "TwqGvy63uVV3",
        "outputId": "36bfc4d4-24bd-4c57-f689-0e8711028073"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but this document focuses on the deployment of AI models in Saudi Arabia and doesn't contain information about the strengths and weaknesses of different AI models.  Therefore, I cannot answer your question using the provided text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"كيف قاعدين يستخدمون نماذج الذكاء الاصطناعي التوليدي في السعودية؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "fsLslXU5urXg",
        "outputId": "9edbd293-8bc0-4855-ce86-693427e08c45"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرحباً بك!  يستخدم نموذج جوجل Gemini في السعودية من خلال شراكة بين صندوق الاستثمارات العامة (PIF) و جوجل كلاود.  هذا المركز  يُدمج نماذج جوجل Gemini مع بيانات عربية لخلق قدرات ذكاء اصطناعي باللغة العربية،  مُصممة خصيصاً للتطبيقات السعودية.  كما تم إطلاق نموذج Alibaba's Qwen 2 في السعودية، ويركز على تقديم أداء ذكاء اصطناعي متطور مُصمم للشركات المحلية ودعم اللغة العربية.  أيضاً، تستخدم منصة Zoom  بنية تحتية سحابية من Oracle في المملكة لتشغيل مساعدين ذكاء اصطناعي محلياً، لضمان بقاء البيانات داخل المملكة والامتثال للوائح السعودية.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"could you summarize the first article of the Personal Data Protection Law\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "WrptaQ6I2VZz",
        "outputId": "bd19a2ff-73fd-4f11-935f-2cae76b759e6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the purpose of implementing this Law, the following terms shall have the meanings assigned thereto, unless the context requires otherwise:  The definitions include the Law itself (Personal Data Protection Law), Regulations (Implementing Regulations of the Law), Competent Authority (to be determined by a resolution of the Council of Ministers), Personal Data (any data that may lead to identifying an individual, including name, personal identification number, addresses, etc.), and Processing (any operation carried out on Personal Data by any means, whether manual or automated).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"what is the first مادة من نظام حماية البيانات الشخصية؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "b2DoJyWW3zGX",
        "outputId": "19b78761-c0d2-4dc1-a374-72163351e109"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرحباً بك!  المادة الأولى من نظام حماية البيانات الشخصية تُعرّف المصطلحات المستخدمة في القانون، مثل \"القانون\" نفسه، و\"اللوائح\"، و\"الجهة المختصة\"، و\"البيانات الشخصية\"، و\"المعالجة\".\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"what is the punishment for data violation\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "d5Ahx6MM39Tf",
        "outputId": "34a0ac91-736b-482d-b771-b149b199036e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, publishing sensitive data with the intent to harm or for personal benefit is punishable by imprisonment not exceeding two years, a fine not exceeding three million Riyals, or both.  The Public Prosecution is responsible for investigating and prosecuting these violations.  Further details regarding other data violations and their punishments are not available in this document.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"give me some informations about domestic airports\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "LWQps0q7HPze",
        "outputId": "6193d08e-9a98-4118-d35d-f766a1d57c48"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided data, I can tell you about the number of departing passengers from Riyadh's domestic airport in several years.  In 2008, there were 39,046,870 departing passengers; in 2009, 41,848,150; in 2014, 65,644,640; and in 2016, 70,341,350.  The latitude and longitude coordinates for Riyadh's domestic airport are 24.9427121, 46.7123544.  I do not have information about other domestic airports.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}