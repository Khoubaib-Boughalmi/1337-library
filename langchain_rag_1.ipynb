{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW+BylZmhmqIBodxHDpO3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khoubaib-Boughalmi/1337-library/blob/main/langchain_rag_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDhuMQA5cW1a",
        "outputId": "2d0c1dde-8e19-4974-da63-b15b4cb4e1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade langchain-core langchain-text-splitters faiss-cpu langchain-community langgraph beautifulsoup4 langchain-google-vertexai google-cloud-aiplatform pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import os\n",
        "\n",
        "pdf_directory = \"/content/data\"\n",
        "pdf_docs = []\n",
        "\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(os.path.join(pdf_directory, filename))\n",
        "        pdf_docs.extend(loader.load())\n"
      ],
      "metadata": {
        "id": "Ptyqrb7zsVLi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b1e67e96-e156-4d74-841c-1886a4182414"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2885e320cb5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpdf_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Only keep post title, headers, and content from the full HTML.\n",
        "bs4_strainer = bs4.SoupStrainer(id=\"bodyContent\")\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://en.wikipedia.org/wiki/Saudi_Authority_for_Data_and_Artificial_Intelligence\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "docs = loader.load() # 1 doc (1 page)\n",
        "\n",
        "assert len(docs) == 1\n",
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "id": "s7yFkJTldAFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content[:1000])"
      ],
      "metadata": {
        "id": "2XnfTQSsdBuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = docs + pdf_docs\n"
      ],
      "metadata": {
        "id": "5BcV1yG-srq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    add_start_index=True,\n",
        ")\n",
        "all_splits = text_splitter.split_documents(all_docs)\n",
        "print(f\"Split into {len(all_splits)} chunks\")"
      ],
      "metadata": {
        "id": "sAMhPKQveBfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_splits[2])"
      ],
      "metadata": {
        "id": "t1gPTlngeMal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/gen-lang-client-0716959645-1c6625495b1d.json\""
      ],
      "metadata": {
        "id": "nFc_sGJLoXgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat {os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")}"
      ],
      "metadata": {
        "id": "Sy0x0_zwoi8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_vertexai import VertexAIEmbeddings\n",
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.docstore.document import Document\n",
        "# from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "\n",
        "# # os.environ[\"GOOGLE_CLOUD_REGION\"] = \"me-central2\"\n",
        "\n",
        "# # Initialize Vertex AI Embeddings\n",
        "# embedding_model = VertexAIEmbeddings(\n",
        "#     model_name=\"textembedding-gecko@001\",  # Required!\n",
        "# )\n",
        "\n",
        "# # Initialize Vertex AI Embeddings\n",
        "# embedding_model = VertexAIEmbeddings()\n",
        "\n",
        "# # Sample documents\n",
        "# documents = [\n",
        "#     Document(page_content=\"LangChain is a framework for building LLM-powered apps.\"),\n",
        "#     Document(page_content=\"Google Vertex AI provides powerful models like Gemini.\"),\n",
        "# ]\n",
        "\n",
        "# # Initialize with an embedding model\n",
        "# vector_store = InMemoryVectorStore(embedding=embedding_model())\n"
      ],
      "metadata": {
        "id": "aX6L3Qnjpjia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize local embedding model using sentence-transformers\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Create FAISS vector store using local embeddings\n",
        "content_list = [doc.page_content for doc in all_splits]\n",
        "vector_store = FAISS.from_texts(content_list, embedding_model)\n"
      ],
      "metadata": {
        "id": "PQlKm-TBgMGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str) -> list[float]:\n",
        "    return embedding_model.embed_query(text)\n"
      ],
      "metadata": {
        "id": "VqNjQvE-wWmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query: str):\n",
        "    return vector_store.similarity_search(query)\n"
      ],
      "metadata": {
        "id": "GbKa6DWTvXMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rag_prompt(query, relevant_passage):\n",
        "    relevant_passage = ' '.join(relevant_passage)\n",
        "    return (\n",
        "        f\"You are a helpful and informative chatbot that answers questions using text from the reference passage included below. \"\n",
        "        f\"Respond in a complete sentence and make sure that your response is easy to understand for everyone. \"\n",
        "        f\"Maintain a friendly and conversational tone. If the passage is irrelevant, feel free to ignore it.\\n\\n\"\n",
        "        f\"QUESTION: '{query}'\\n\"\n",
        "        f\"PASSAGE: '{relevant_passage}'\\n\\n\"\n",
        "        f\"ANSWER:\"\n",
        "    )"
      ],
      "metadata": {
        "id": "TQEVd5NzNS1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.generativeai as genai\n",
        "\n",
        "# genai.configure(api_key=\"AIzaSyDXM2rYFwObTTIFrJLMgVTvfjEaGwqj_D0\")\n",
        "# def generate_response(user_prompt):\n",
        "#     model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
        "#     answer = model.generate_content(user_prompt)\n",
        "#     return answer.text"
      ],
      "metadata": {
        "id": "78JQRUzhPLDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDXM2rYFwObTTIFrJLMgVTvfjEaGwqj_D0\")\n",
        "def generate_response(user_prompt):\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash-002')\n",
        "    answer = model.generate_content(user_prompt)\n",
        "    return answer.text"
      ],
      "metadata": {
        "id": "DZVtEA7-NYdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query):\n",
        "    relevant_text = retrieve(query)\n",
        "    text = \" \".join([doc.page_content for doc in relevant_text])\n",
        "    prompt = make_rag_prompt(query, relevant_passage=text)\n",
        "    answer = generate_response(prompt)\n",
        "    return answer\n",
        "answer = generate_answer(\"ين هي الهيئة السعودية للبيانات والذكاء الاصطناعي\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "bfCXsUoOvhuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش مزوّدي الخدمة الموجودين في السعودية؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "sN0HwQaiNXba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش اسم نموذج علي بابا؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "3JUAoW2tixP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش أكبر النماذج المتوفرة؟ وإذا تقدر، عطِني أرقام.\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "o5lVxpL4uCjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"وش نقاط القوة والضعف في كل نموذج؟\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "TwqGvy63uVV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = generate_answer(\"كيف قاعدين يستخدمون نماذج الذكاء الاصطناعي التوليدي في السعودية؟\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "fsLslXU5urXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}